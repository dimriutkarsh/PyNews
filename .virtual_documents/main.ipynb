import requests
import pandas as pd
import numpy as np


a= requests.get("https://www.news18.com/")
with open (f"htmls/page1.html","w",encoding="utf-8") as f:
    f.write(a.text)
    print(f"DOWNLOADED PAGE SUCCESSFULLY!")


from bs4 import BeautifulSoup

with open("htmls/page1.html", "r", encoding="utf-8") as file:
    html_content = file.read()



soup = BeautifulSoup(html_content,"html.parser")
soup.h1.text


articles = soup.find_all("a", class_="jsx-6cc628dcbd17db93")
articles


list_items = soup.find_all("li")

news_data = []

for item in list_items:
    a_tag = item.find("a")
    if a_tag:
        title = a_tag.get_text(strip=True)
        link = a_tag.get("href")

        if link and not link.startswith("http"):
            link = "https://www.news18.com" + link

        if title and link:
            news_data.append([title, link])

print(news_data)


# Create DataFrame
df = pd.DataFrame(news_data, columns=["Title", "Link"])

# Save to CSV
df.to_csv("news18_local_html.csv", index=False, encoding="utf-8")

# Show top 5 rows
df.head()






